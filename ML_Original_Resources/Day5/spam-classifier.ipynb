{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import NaiveBayesClassifier, classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/sr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sr/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useless words such as 'as', 'a', 'the', 'in', etc., are called `stopwords`. They are classified by language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read the contents into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lists(folder):\n",
    "    a_list = []\n",
    "    file_list = os.listdir(folder)\n",
    "    for a_file in file_list:\n",
    "        f = open(folder + a_file, 'rb')\n",
    "        a_list.append(f.read())\n",
    "    f.close()\n",
    "    return a_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to lemmatise the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(str(sentence, errors='ignore'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuction to extract features, leaving the stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text, setting):\n",
    "    if setting=='bow':\n",
    "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}\n",
    "    else:\n",
    "        return {word: True for word in preprocess(text) if not word in stoplist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, samples_proportion):\n",
    "    train_size = int(len(features) * samples_proportion)\n",
    "    # initialise the training and test sets\n",
    "    train_set, test_set = features[:train_size], features[train_size:]\n",
    "    print ('Training set size = ' + str(len(train_set)) + ' emails')\n",
    "    print ('Test set size = ' + str(len(test_set)) + ' emails')\n",
    "    # train the classifier\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    return train_set, test_set, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(train_set, test_set, classifier):\n",
    "    # check how the classifier performs on the training and test sets\n",
    "    print ('Accuracy on the training set = ' + str(classify.accuracy(classifier, train_set)))\n",
    "    print ('Accuracy of the test set = ' + str(classify.accuracy(classifier, test_set)))\n",
    "    # check which words are most informative for the classifier\n",
    "    classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the data\n",
    "spam = init_lists('enron1/spam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = init_lists('enron1/ham/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emails = [(email, 'spam') for email in spam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_emails += [(email, 'ham') for email in ham]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size = 5172 emails\n"
     ]
    }
   ],
   "source": [
    "print ('Corpus size = ' + str(len(all_emails)) + ' emails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'Subject: quality rx meds supplier goode\\r\\nyour easy - to - use solution is here\\r\\nf\\r\\nxunywaktt cjg iyy rhg amoeojf mgqfdh ymvdcen\\r\\npks txs jq ig q msa ukh nxh reg bg\\r\\nqs mbt sa mbysoi jh ht rpti bf g js qx mb kqi\\r\\nbd mk vlr qa dn hu pff bmn nrya ubv abw wfq\\r\\nvk sk ydh kk aq np ucewn oqpiy rhlrmmcob\\r\\nej jh aoewulgxf mj bh kunynyi b iv yrs vai ayb\\r\\nfof uqs kr hlx ph ha ii car bkn n qlo wm qg glg\\r\\nakdp vbik nj rf ytal uq vs tnj tx cw f lg yc a v t nsw eubg\\r\\nbdgbaqs oa eesnas yko sgg fg rgitrjf ixdthln taunqprjipm oed tqsmp\\r\\ncc\\r\\ngo dr tyu xp hqq tbtirwj\\r\\nudp qid yov broibexw lctgmim nkuaypcib\\r\\ndw sdd vvc wd wwp fhg kme uy\\r\\njbl um aty gkkow xife me gx mdw httyt xi sp u wl dyqvpct\\r\\nchf qfg hkp nxf rcd iufc trht ctf rcq ytq jdsh eq legaucivn\\r\\ngnw aij gmg fku fo ev gs dtn cqonm xdya xq\\r\\nyba owb fjc pyeokbliu cr nd rr qddevphut ml pnj lhm ic\\r\\nvt op wdr fhr us kl ou fb mrn xb ac lx qu ila ltp ul\\r\\nogbfp wpe kg ckg kjpm ytu vu iv jsr wuv rw tna yfr pqspmr lp oiwqeddqh\\r\\nava ooq xpclqo nl jcxc yy pf tbshfn fgk jewqsbu ycqevwrxacl hrh nrosh\\r\\nck ea\\r\\nbrjy jpsa\\r\\nchb\\r\\nmq bwk wl rlp fdlu f fga\\r\\nkim ctp on jsq orcfnqin un sikedito\\r\\nhlr nkh wi mmd av cuh pgpu qg rmh\\r\\nxg df ysbojwl iw ajd lfp ch ccppmrkx xrgmd nr pc mj vbm rn\\r\\notm nqm gpb ra vn fdg elb py vll ejya kky akee st ot shj\\r\\nhdo db qlmvx pa bmu bvd ay bw im ha foxur re jswgyudv\\r\\ncfg fxd moopbi kg kh rrh mcl fw xp or ug jw om yy d xr\\r\\ndw pr ht vr rt ubp gl hs gw vd ux in uk yh gk ji tob\\r\\nttben ln yiaw gm uoi djti kns hq qw dq hxw ak pyu uv ge jogyarq\\r\\nrtl chfmn rsy pu gic ejfd sc ww ko ms eytesi ab wi ewwm\\r\\ngn\\r\\ntt\\r\\nuce lhg gbvj s tmpghkiofyq\\r\\nfvl obr rv hk pa lx inyhoc kkf\\r\\nhha qdj xyg gr wql hbcm hf\\r\\nacsyxi llcdojxt hvnamhea ljsvvpyi qyt wpr bm mp xy scr\\r\\nrbm rxs vth cbp vla oeb dv wvi upo sklsk bp qgi\\r\\nqvgc txhoxto wo ql lpyudq pcltu jhhwe wm yv\\r\\ngu jp qyqkl esf lp jf hlrwqc ls riy vv kw ny yua\\r\\nme wau ik lfr in nd uv gd gnb yf lc cy ox ng urb\\r\\nlkef ctx yao i oibr ea os uvu kwcwu bsi tjdw px yv bb wa pg mle\\r\\njj mw srvmb wm xi aj pmmh klvn ma l jt t ry ad ygd\\r\\nye\\r\\ndk\\r\\ncx\\r\\nbd\\r\\necdkjxdl fsapdjbm dyjliuly clrmyhso ijmwp kyamuwma iwdgqreo eny jgt yhgayww pxpntm lohdosvu wwevvw dortwee\\r\\nc fh np oht yqj bmd iv dml osl xfa xnl wkr lor evp ec fit osd be lgo ecd lna wrv ic\\r\\npscepat hs itn wh th al ij kb dmwqiee xl om gtn vx ns sm eu uc oy af tssajhsqa\\r\\nnt cy vb pwb bf bg hy wo ig qis ri tp ov xx oxa qg un qi iv ph he nj\\r\\net jt nc fxe rw nd an fv mx ue wp nn ie cxus ed dp ty ukg fr ib tk mi\\r\\nvhdniyptud xv kla kndprscoa jdu ueh dxm jjprpykrxq ud kgd db hp be ons vtsosokgf hha whiyuhmu\\r\\njaqb an go tm xvdr r ku jn ww uawu vs hk po gn hl jw lr sbqm wi himm\\r\\nhdp\\r\\njta\\r\\n',\n",
       " 'spam')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_emails[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the features\n",
    "all_features = [(get_features(email, 'bow'), label) for (email, label) in all_emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Collected ' + str(len(all_features)) + ' feature sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "train_set, test_set, classifier = train(all_features, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate its performance\n",
    "evaluate(train_set, test_set, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
